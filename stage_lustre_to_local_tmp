#!/usr/bin/env bash
set -euo pipefail

# stage_lustre_to_local_tmp
#
# Replicates SRC (directory OR file) to /tmp on EACH allocated node using dsync + mpiexec.
# You can choose how many MPI ranks per node to run dsync with.
#
# Logging (optional):
#   Logs are written on the *launcher node* under /tmp in a per-run logs
#   directory, then archived+compressed into the current working directory.
#
#   Enable logging with: -L
#
# Usage:
#   ./stage_lustre_to_local_tmp -s /lustre/path/mydir
#   ./stage_lustre_to_local_tmp -s /lustre/path/myfile.bin
#   ./stage_lustre_to_local_tmp -s /lustre/path/myfile.bin -n local_name.bin
#   ./stage_lustre_to_local_tmp -s /lustre/path/mydir -r 4
#   ./stage_lustre_to_local_tmp -s /lustre/path/mydir -L
#
# Result on each node:
#   If SRC is a directory: /tmp/<name>/...
#   If SRC is a file:      /tmp/<name>

SRC=""
NAME=""
RANKS_PER_NODE=1

LOGGING=0   # 1=on, 0=off
LOGS_DIR=""
LOGS_BASE=""
ARCHIVE=""

usage() {
  cat >&2 <<EOF
Usage: $0 -s SRC [-n DEST_NAME] [-r RANKS_PER_NODE] [-L]

  -s  Source path on Lustre (directory OR file)
  -n  Destination name under /tmp
        * dir src: default basename(SRC)
        * file src: default basename(SRC)
  -r  MPI ranks per node for dsync (default: 1)
  -L  Enable logging (archive of per-node log files)

Examples:
  $0 -s /lustre/project/data_dir -n data_local -r 8
  $0 -s /lustre/project/file.dat -n file_local.dat -r 4
  $0 -s /lustre/project/data_dir -L
EOF
  exit 2
}

while getopts ":s:n:r:Lh" opt; do
  case "${opt}" in
    s) SRC="${OPTARG}" ;;
    n) NAME="${OPTARG}" ;;
    r) RANKS_PER_NODE="${OPTARG}" ;;
    L) LOGGING=1 ;;
    h) usage ;;
    \?) echo "Unknown option: -${OPTARG}" >&2; usage ;;
    :)  echo "Missing argument for -${OPTARG}" >&2; usage ;;
  esac
done

if [[ -z "${SRC}" ]]; then
  echo "ERROR: -s SRC is required" >&2
  usage
fi

if [[ ! -e "${SRC}" ]]; then
  echo "ERROR: SRC does not exist: ${SRC}" >&2
  exit 1
fi

SRC_IS_DIR=0
SRC_IS_FILE=0
if [[ -d "${SRC}" ]]; then
  SRC_IS_DIR=1
elif [[ -f "${SRC}" ]]; then
  SRC_IS_FILE=1
else
  echo "ERROR: SRC must be a regular file or directory: ${SRC}" >&2
  exit 1
fi

if ! [[ "${RANKS_PER_NODE}" =~ ^[0-9]+$ ]] || [[ "${RANKS_PER_NODE}" -lt 1 ]]; then
  echo "ERROR: RANKS_PER_NODE must be a positive integer (got: ${RANKS_PER_NODE})" >&2
  exit 1
fi

if [[ -z "${NAME}" ]]; then
  NAME="$(basename "${SRC}")"
fi

DEST_PARENT="/tmp"
DEST_PATH="${DEST_PARENT}/${NAME}"   # If SRC is dir => destination dir; if SRC is file => destination file path

# ---- Logs directory (launcher node /tmp) ----
if [[ "${LOGGING}" -eq 1 ]]; then
  RUN_TS="$(date +%Y%m%d_%H%M%S)"
  LOGS_DIR="/tmp/${NAME}_logs_${RUN_TS}"
  LOGS_BASE="$(basename "${LOGS_DIR}")"
  ARCHIVE="${PWD}/${LOGS_BASE}.tar.gz"
  mkdir -p "${LOGS_DIR}"
fi

# ---- Get node list from common schedulers (SLURM, PBS) ----
get_nodes() {
  if [[ -n "${SLURM_NODELIST:-}" ]]; then
    scontrol show hostnames "${SLURM_NODELIST}"
  elif [[ -n "${PBS_NODEFILE:-}" && -f "${PBS_NODEFILE:-}" ]]; then
    sort -u "${PBS_NODEFILE}"
  else
    echo "ERROR: Could not determine allocated nodes (SLURM_NODELIST or PBS_NODEFILE not set)." >&2
    exit 1
  fi
}

mapfile -t NODES < <(get_nodes)

if [[ "${#NODES[@]}" -eq 0 ]]; then
  echo "ERROR: Node list is empty." >&2
  exit 1
fi

# ---- Detect mpiexec host option flavor ----
MPIEXEC_HOST_OPT=""
if mpiexec --help 2>&1 | grep -q -- '--host'; then
  MPIEXEC_HOST_OPT="--host"
elif mpiexec --help 2>&1 | grep -q -- '-hosts'; then
  MPIEXEC_HOST_OPT="-hosts"
elif mpiexec --help 2>&1 | grep -q -- '-host'; then
  MPIEXEC_HOST_OPT="-host"
else
  echo "ERROR: Couldn't detect a usable mpiexec host option (--host/-host/-hosts)." >&2
  echo "Hint: edit MPIEXEC_HOST_OPT manually for your MPI implementation." >&2
  exit 1
fi

echo "Source:                    ${SRC}"
if [[ "${SRC_IS_DIR}" -eq 1 ]]; then
  echo "Source type:               directory"
else
  echo "Source type:               file"
fi
echo "Dest (per node):           ${DEST_PATH}"
echo "Ranks per node (dsync):    ${RANKS_PER_NODE}"
if [[ "${LOGGING}" -eq 1 ]]; then
  echo "Logs (launcher /tmp):      ${LOGS_DIR}"
else
  echo "Logs (launcher /tmp):    disabled"
fi
echo "Nodes (${#NODES[@]}):      ${NODES[*]}"
echo "Using mpiexec host option: ${MPIEXEC_HOST_OPT}"
echo

# ---- Set `get_cpu_bind_aurora` location ----
SCRIPT_DIR="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" && pwd)"
if [[ -x "$SCRIPT_DIR/get_cpu_bind_aurora" ]]; then
  GET_CPU_BIND_AURORA="$SCRIPT_DIR/get_cpu_bind_aurora"
else
  GET_CPU_BIND_AURORA="get_cpu_bind_aurora"
fi

# Helper: run a command in background with optional log capture.
# Usage: run_bg <node> <stage> <command...>
run_bg() {
  local node="$1"; shift
  local stage="$1"; shift

  if [[ "${LOGGING}" -eq 1 ]]; then
    "$@" >"${LOGS_DIR}/${stage}.${node}.log" 2>&1 &
  else
    "$@" &
  fi
}

# ---- Ensure destination parent exists on each node (local /tmp) ----
echo "Creating ${DEST_PARENT} on each node..."
pids=()
for node in "${NODES[@]}"; do
  run_bg "${node}" "mkdir" mpiexec -n 1 ${MPIEXEC_HOST_OPT} "${node}" mkdir -p "${DEST_PARENT}"
  pids+=("$!")
done

mkdir_fail=0
for i in "${!pids[@]}"; do
  pid="${pids[$i]}"
  node="${NODES[$i]}"
  if ! wait "${pid}"; then
    if [[ "${LOGGING}" -eq 1 ]]; then
      echo "ERROR: mkdir failed on ${node}. See ${LOGS_DIR}/mkdir.${node}.log" >&2
    else
      echo "ERROR: mkdir failed on ${node}." >&2
    fi
    mkdir_fail=1
  else
    echo "OK: mkdir ${node}"
  fi
done
echo

# ---- If SRC is a file, touch destination file on each node before transfer ----
touch_fail=0
if [[ "${SRC_IS_FILE}" -eq 1 ]]; then
  echo "Touching destination file on each node before dsync: ${DEST_PATH}"
  pids=()
  for node in "${NODES[@]}"; do
    # Ensure parent dir exists (DEST_PARENT is /tmp; if you ever allow subpaths, this still works)
    run_bg "${node}" "touch" \
      mpiexec -n 1 ${MPIEXEC_HOST_OPT} "${node}" bash -lc "mkdir -p \"$(dirname "${DEST_PATH}")\" && : > \"${DEST_PATH}\""
    pids+=("$!")
  done

  for i in "${!pids[@]}"; do
    pid="${pids[$i]}"
    node="${NODES[$i]}"
    if ! wait "${pid}"; then
      if [[ "${LOGGING}" -eq 1 ]]; then
        echo "ERROR: touch failed on ${node}. See ${LOGS_DIR}/touch.${node}.log" >&2
      else
        echo "ERROR: touch failed on ${node}." >&2
      fi
      touch_fail=1
    else
      echo "OK: touch ${node}"
    fi
  done
  echo
fi

# ---- Run dsync on each node ----
module load mpifileutils
echo "Copying with dsync (${RANKS_PER_NODE} ranks per node)..."
pids=()
for node in "${NODES[@]}"; do
  run_bg "${node}" "dsync" \
    mpiexec -n "${RANKS_PER_NODE}" $(${GET_CPU_BIND_AURORA} ${RANKS_PER_NODE}) ${MPIEXEC_HOST_OPT} "${node}" \
      dsync -v "${SRC}" "${DEST_PATH}"
  pids+=("$!")
done

dsync_fail=0
for i in "${!pids[@]}"; do
  pid="${pids[$i]}"
  node="${NODES[$i]}"
  if ! wait "${pid}"; then
    if [[ "${LOGGING}" -eq 1 ]]; then
      echo "ERROR: dsync failed on ${node}. See ${LOGS_DIR}/dsync.${node}.log" >&2
    else
      echo "ERROR: dsync failed on ${node}." >&2
    fi
    dsync_fail=1
  else
    echo "OK: dsync ${node}"
  fi
done

# ---- Archive and compress logs to current working directory ----
if [[ "${LOGGING}" -eq 1 ]]; then
  echo
  echo "Archiving logs to: ${ARCHIVE}"
  tar -C /tmp -czf "${ARCHIVE}" "${LOGS_BASE}"
  echo "Logs archived: ${ARCHIVE}"
fi

# ---- Final status ----
if [[ "${mkdir_fail}" -ne 0 || "${touch_fail}" -ne 0 || "${dsync_fail}" -ne 0 ]]; then
  if [[ "${LOGGING}" -eq 1 ]]; then
    echo "One or more nodes failed. Check logs in ${ARCHIVE}" >&2
  else
    echo "One or more nodes failed." >&2
  fi
  exit 1
fi

echo
echo "All nodes now have: ${DEST_PATH}"

